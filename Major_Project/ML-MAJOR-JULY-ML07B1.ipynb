{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verzeo - Major Project (ML-JULY-B1)\n",
    "\n",
    "### Done by : Sanjay Marreddi  \n",
    "### Email Id  : sanjay.marreddi.19041@iitgoa.ac.in\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let us import the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us read the given Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information = pd.read_excel('information.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "information.isnull().sum() # Checking the Missing Values in each Column of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HaetMap of the Correlation Matrix\n",
    "sns.heatmap(information.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"retweet_count\", data=information.loc[1:100,:], hue = 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"tweet_count\", data=information.loc[1:50,:], hue = 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information =  information[[\"gender\", \"name\",\"description\", \"gender:confidence\",\"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dropping the rows with NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information = information.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning of \"description\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_stopwords = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only those rows which has type of description str. \n",
    "temp=[]\n",
    "for i in range(information.shape[0]):\n",
    "    temp.append(type(information['description'].values[i]) == str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information = information.loc[temp,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "# Data Cleaning using regex.\n",
    "information['cleaned_description'] = information['description'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning of \"text\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "information['cleaned_text'] = information['text'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only those rows with full confidence in gender\n",
    "information = information[information[\"gender:confidence\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_information =  information[[\"name\",\"cleaned_text\",\"cleaned_description\"]]  #Independent Variables\n",
    "\n",
    "y_information = information[[\"gender\"]]   # Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X_information.shape)\n",
    "X_information.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_information.shape)\n",
    "y_information.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding the gender column for ease of Calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_information['gender_encoded'] = le.fit_transform(y_information[\"gender\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_information = y_information[[\"gender_encoded\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_information.shape)\n",
    "y_information.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Machine Learning Modelling\n",
    "\n",
    "## 1. Classification using Naive Bayes Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X_information.shape)\n",
    "X_information.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_information.shape)\n",
    "y_information.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into Training and Testing Sets\n",
    "\n",
    "Train_X_Nb, Test_X_Nb, Train_Y_Nb, Test_Y_Nb = train_test_split(X_information['cleaned_description'],y_information['gender_encoded'],test_size = 0.01, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Label Encoding for both Training and Testing Sets.\n",
    "\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y_Nb = Encoder.fit_transform(Train_Y_Nb)\n",
    "Test_Y_Nb = Encoder.fit_transform(Test_Y_Nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming text to feature vectors that can be used as input to estimator.\n",
    "\n",
    "T_vect = TfidfVectorizer(max_features=5000)\n",
    "T_vect.fit(X_information['cleaned_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the Train and Test sets.\n",
    "\n",
    "Train_X_Nb_T = T_vect.transform(Train_X_Nb)\n",
    "Test_X_Nb_T = T_vect.transform(Test_X_Nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the NB classifier.\n",
    "\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Nb_T,Train_Y_Nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels on validation dataset.\n",
    "\n",
    "predictions_Nb = Naive.predict(Test_X_Nb_T)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy.\n",
    "\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_Nb, Test_Y_Nb)*100)\n",
    
     "# Saving the Output by first converting it into Dataframe and then into CSV File.\n"
     "df = pd.DataFrame(data=predictions_Nb, columns=["result"])\n",
     "df.to_csv("result.csv")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification using Support Vector Machine Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X_information.shape)\n",
    "X_information.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (y_information.shape)\n",
    "y_information.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into Training and Testing Sets\n",
    "\n",
    "Train_X_Svm, Test_X_Svm, Train_Y_Svm, Test_Y_Svm = train_test_split(X_information['cleaned_description'],y_information['gender_encoded'],test_size = 0.01, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Label Encoding for both Training and Testing Sets.\n",
    "\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y_Svm = Encoder.fit_transform(Train_Y_Svm)\n",
    "Test_Y_Svm = Encoder.fit_transform(Test_Y_Svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming text to feature vectors that can be used as input to estimator.\n",
    "\n",
    "T_vect = TfidfVectorizer(max_features=5000)\n",
    "T_vect.fit(X_information['cleaned_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the Train and Test sets.\n",
    "\n",
    "Train_X_Svm_T = T_vect.transform(Train_X_Svm)\n",
    "Test_X_Svm_T = T_vect.transform(Test_X_Svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the classifier\n",
    "\n",
    "SVM = svm.SVC(C=2, kernel='linear', degree=2, gamma='auto')\n",
    "SVM.fit(Train_X_Svm_T,Train_Y_Svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels on validation dataset\n",
    "\n",
    "predictions_Svm = SVM.predict(Test_X_Svm_T)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_Svm, Test_Y_Svm)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification using Logistic Regression Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X_information.shape)\n",
    "X_information.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_information.shape)\n",
    "y_information.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into Training and Testing Sets\n",
    "\n",
    "Train_X_Lr, Test_X_Lr, Train_Y_Lr, Test_Y_Lr = train_test_split(X_information['cleaned_description'],y_information['gender_encoded'],test_size = 0.01, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Label Encoding for both Training and Testing Sets.\n",
    "\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y_Lr = Encoder.fit_transform(Train_Y_Lr)\n",
    "Test_Y_Lr = Encoder.fit_transform(Test_Y_Lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming text to feature vectors that can be used as input to estimator.\n",
    "\n",
    "T_vect = TfidfVectorizer(max_features=5000)\n",
    "T_vect.fit(X_information['cleaned_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the Train and Test sets.\n",
    "\n",
    "Train_X_Lr_T = T_vect.transform(Train_X_Lr)\n",
    "Test_X_Lr_T = T_vect.transform(Test_X_Lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training dataset on the classifier\n",
    "\n",
    "lr = LogisticRegression(max_iter = 1000)\n",
    "lr.fit(Train_X_Lr_T,Train_Y_Lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the labels on validation dataset\n",
    "\n",
    "predictions_Lr = lr.predict(Test_X_Lr_T)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "\n",
    "print(\"LR Accuracy Score -> \",accuracy_score(predictions_Lr, Test_Y_Lr)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Machine Learning Modelling -> Choosing best Algo based on Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### From above Models, Accuracy obtained through\n",
    "\n",
    "1. Naive Bayes Algorithm           is **71.42857142857143 %**\n",
    "\n",
    "2. Support Vector Machine Algorithm is **68.0672268907563 %**\n",
    "\n",
    "3. Logistic Regression Algorithm is  **70.58823529411765 %**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### So, For the given data set and the used hyperparameters, Based on the accuracy score , We can say **Naive Bias Algorithm is best** in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions on DataSet \n",
    "\n",
    "## 1.What are the most common emotions/words used by Males and Females?\n",
    "\n",
    "#### 1.a For Males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data and dropping null values\n",
    "\n",
    "information = pd.read_excel('information.xlsx')\n",
    "information =  information[[\"gender\", \"name\",\"description\", \"gender:confidence\",\"text\"]]\n",
    "information = information.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only those rows which has type of description str. \n",
    "temp=[]\n",
    "for i in range(information.shape[0]):\n",
    "    temp.append(type(information['description'].values[i]) == str)    \n",
    "information = information.loc[temp,:]\n",
    "\n",
    "\n",
    "# Data Cleaning\n",
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "information['cleaned_description'] = information['description'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "information['cleaned_text'] = information['text'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "\n",
    "\n",
    "# Feature Selection & Engineering\n",
    "information = information[information[\"gender:confidence\"]==1]\n",
    "X_information =  information[[\"gender\", \"name\",\"cleaned_text\",\"cleaned_description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_information.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only those rows with gender as \"Male\"\n",
    "\n",
    "X_info_M = X_information.loc[ (X_information.gender == \"male\" )] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_info_M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Counter.\n",
    "words_M = Counter()\n",
    "\n",
    "# Taking the column named \"cleaned_text\" and counting the frequency of each word.\n",
    "X_info_M['cleaned_text'].str.split().apply(words_M.update)\n",
    "\n",
    "print(words_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the Dictionary with the Values in Descending Order\n",
    "{k: v for k, v in sorted(words_M.items(), key=lambda item: item[1], reverse =True )}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So,From the above calculation, \n",
    "###### The Most Common WORD  used by Males is \"I\" which was used 1460 times !\n",
    "###### The most Common EMOTION used by Males is \"love\" which was used 158 times !!\n",
    "\n",
    "#### 1.b For Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only those rows with gender as \"Female\"\n",
    "\n",
    "X_info_F = X_information.loc[ (X_information.gender == \"female\" )] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_info_F.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Counter.\n",
    "words_F = Counter()\n",
    "\n",
    "# Taking the column named \"cleaned_text\" and counting the frequency of each word.\n",
    "X_info_F['cleaned_text'].str.split().apply(words_F.update)\n",
    "\n",
    "print(words_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the Dictionary with the Values in Descending Order\n",
    "{k: v for k, v in sorted(words_F.items(), key=lambda item: item[1], reverse =True )}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So,From the above calculation, \n",
    "###### The Most Common WORD  used by Females is \"I\" which was used 2311 times !\n",
    "###### The most Common EMOTION used by Females is \"love\" which was used 275 times !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Which Gender has more number of tweet count ? On an average what is the tweet_count by each gender ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "information = pd.read_excel('information.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the required features\n",
    "information = information[[\"gender\", \"tweet_count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going through each row and summing up the number of tweets for each gender and storing in a Dictionary\n",
    "\n",
    "tweet_counter= {}\n",
    "for i in range(information.shape[0]):\n",
    "    for gen in [\"male\", \"female\",\"brand\",\"unknown\"]: \n",
    "        if information.gender[i] == gen :\n",
    "            if not gen in tweet_counter:\n",
    "                tweet_counter[gen] = information.tweet_count[i]\n",
    "            else:\n",
    "                tweet_counter[gen] += information.tweet_count[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the Dictionary with the Values in Descending Order\n",
    "{k: v for k, v in sorted(tweet_counter.items(), key=lambda item: item[1], reverse =True )}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### So, From above it is clear that Gender \"brand\" has more number of tweet count  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the users with respect to gender\n",
    "\n",
    "gender_counter = information.gender.value_counts().to_dict()\n",
    "gender_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the average number of tweets per gender\n",
    "\n",
    "avg_tweet ={}\n",
    "for i in [\"male\", \"female\",\"brand\",\"unknown\"]: \n",
    "    avg_tweet[i] = tweet_counter[i]/gender_counter[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The above dictionary shows the average number of Tweets per Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Which user_timezone has the maximum number of tweet_count ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "information = pd.read_excel('information.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "information = information[[\"tweet_count\",\"user_timezone\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "information.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the rows with user_name and summing the tweet_count per each group\n",
    "time_zone_df = information.groupby(\"user_timezone\").apply(lambda df : df.tweet_count.sum() )\n",
    "\n",
    "# Converting the dataframe into dictionary\n",
    "time_zone= time_zone_df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the Dictionary with the Values in Descending Order\n",
    "\n",
    "{k: v for k, v in sorted(time_zone.items(), key=lambda item: item[1], reverse =True )}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### From above Dictionary It is clear that Eastern Time (US & Canada) has maximum number of Tweet Counts from users"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
